{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50a75e06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Stacking summary ===\n",
      "01. chair_squats\n",
      "    output, /home/jupyter-yin10/EEG_HAR/NEW/data/2_EEG_window_matched/stacked_by_activity/a1_chair_squats.csv\n",
      "    rows_total, 42853\n",
      "    found, s1:8771 rows, s2:11722 rows, s3:7428 rows, s4:7115 rows, s6:7817 rows\n",
      "    missing, s5:file_missing\n",
      "02. light_stationary_cycling\n",
      "    output, /home/jupyter-yin10/EEG_HAR/NEW/data/2_EEG_window_matched/stacked_by_activity/a2_light_stationary_cycling.csv\n",
      "    rows_total, 37859\n",
      "    found, s1:7641 rows, s2:5011 rows, s3:11404 rows, s4:11478 rows, s6:2325 rows\n",
      "    missing, s5:file_missing\n",
      "03. marching_in_place\n",
      "    output, /home/jupyter-yin10/EEG_HAR/NEW/data/2_EEG_window_matched/stacked_by_activity/a3_marching_in_place.csv\n",
      "    rows_total, 55246\n",
      "    found, s1:10247 rows, s2:9755 rows, s3:7497 rows, s4:7730 rows, s5:11702 rows, s6:8315 rows\n",
      "04. seated_boxing_hooks\n",
      "    output, /home/jupyter-yin10/EEG_HAR/NEW/data/2_EEG_window_matched/stacked_by_activity/a4_seated_boxing_hooks.csv\n",
      "    rows_total, 51247\n",
      "    found, s1:11625 rows, s2:11521 rows, s3:7740 rows, s4:8616 rows, s5:3033 rows, s6:8712 rows\n",
      "05. seated_leg_extensions\n",
      "    output, /home/jupyter-yin10/EEG_HAR/NEW/data/2_EEG_window_matched/stacked_by_activity/a5_seated_leg_extensions.csv\n",
      "    rows_total, 58995\n",
      "    found, s1:15514 rows, s2:7676 rows, s3:11550 rows, s4:9608 rows, s6:14647 rows\n",
      "    missing, s5:file_missing\n",
      "06. seated_medicine_ball_twists\n",
      "    output, /home/jupyter-yin10/EEG_HAR/NEW/data/2_EEG_window_matched/stacked_by_activity/a6_seated_medicine_ball_twists.csv\n",
      "    rows_total, 51374\n",
      "    found, s1:16191 rows, s2:4694 rows, s3:10568 rows, s4:8363 rows, s6:11558 rows\n",
      "    missing, s5:file_missing\n",
      "07. seated_side_bends\n",
      "    output, /home/jupyter-yin10/EEG_HAR/NEW/data/2_EEG_window_matched/stacked_by_activity/a7_seated_side_bends.csv\n",
      "    rows_total, 55960\n",
      "    found, s1:16739 rows, s2:11551 rows, s3:7563 rows, s4:10282 rows, s6:9825 rows\n",
      "    missing, s5:file_missing\n",
      "08. side_stepping\n",
      "    output, /home/jupyter-yin10/EEG_HAR/NEW/data/2_EEG_window_matched/stacked_by_activity/a8_side_stepping.csv\n",
      "    rows_total, 45433\n",
      "    found, s1:11119 rows, s2:11868 rows, s3:10187 rows, s4:4642 rows, s6:7617 rows\n",
      "    missing, s5:file_missing\n",
      "09. standing_heel_to_toe_walk\n",
      "    output, /home/jupyter-yin10/EEG_HAR/NEW/data/2_EEG_window_matched/stacked_by_activity/a9_standing_heel_to_toe_walk.csv\n",
      "    rows_total, 58500\n",
      "    found, s1:14094 rows, s2:11299 rows, s3:10399 rows, s4:11053 rows, s5:2080 rows, s6:9575 rows\n",
      "10. wall_push_ups\n",
      "    output, /home/jupyter-yin10/EEG_HAR/NEW/data/2_EEG_window_matched/stacked_by_activity/a10_wall_push_ups.csv\n",
      "    rows_total, 60162\n",
      "    found, s1:14675 rows, s2:10072 rows, s3:7587 rows, s4:7667 rows, s5:11477 rows, s6:8684 rows\n",
      "\n",
      "Total rows across all outputs, 517,629\n",
      "Files written to, /home/jupyter-yin10/EEG_HAR/NEW/data/2_EEG_window_matched/stacked_by_activity\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from typing import Optional\n",
    "\n",
    "BASE_DIR = Path(\"/home/jupyter-yin10/EEG_HAR/NEW/data/2_EEG_window_matched\")\n",
    "SUBJECTS = [\"s1\",\"s2\",\"s3\",\"s4\",\"s5\",\"s6\"]\n",
    "\n",
    "# Activity slugs and the desired output order\n",
    "ACTIVITIES = [\n",
    "    \"chair_squats\",\n",
    "    \"light_stationary_cycling\",\n",
    "    \"marching_in_place\",\n",
    "    \"seated_boxing_hooks\",\n",
    "    \"seated_leg_extensions\",\n",
    "    \"seated_medicine_ball_twists\",\n",
    "    \"seated_side_bends\",\n",
    "    \"side_stepping\",\n",
    "    \"standing_heel_to_toe_walk\",\n",
    "    \"wall_push_ups\",\n",
    "]\n",
    "\n",
    "OUT_DIR = BASE_DIR / \"stacked_by_activity\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def find_activity_file(folder: Path, activity_slug: str) -> Optional[Path]:\n",
    "    slug = activity_slug.lower()\n",
    "    candidates = []\n",
    "    for p in folder.glob(\"*.csv\"):\n",
    "        name = p.name.lower()\n",
    "        # skip any prior stacked outputs\n",
    "        if \"stacked_by_activity\" in name or name.startswith(\"a1_\") or \"a2_\" in name:\n",
    "            continue\n",
    "        if slug in name:\n",
    "            candidates.append(p)\n",
    "    candidates.sort()\n",
    "    return candidates[0] if candidates else None\n",
    "\n",
    "summary = []\n",
    "for idx, act in enumerate(ACTIVITIES, start=1):\n",
    "    out_path = OUT_DIR / f\"a{idx}_{act}.csv\"\n",
    "\n",
    "    frames = []\n",
    "    cols_s1 = None\n",
    "    found = []\n",
    "    missing = []\n",
    "\n",
    "    for subj in SUBJECTS:\n",
    "        folder = BASE_DIR / subj\n",
    "        if not folder.exists():\n",
    "            missing.append(f\"{subj}:folder_missing\")\n",
    "            continue\n",
    "\n",
    "        f = find_activity_file(folder, act)\n",
    "        if f is None:\n",
    "            missing.append(f\"{subj}:file_missing\")\n",
    "            continue\n",
    "\n",
    "        # Read file, drop matched_window_id if present, add subject column\n",
    "        try:\n",
    "            df = pd.read_csv(f)\n",
    "            if \"matched_window_id\" in df.columns:\n",
    "                df = df.drop(columns=[\"matched_window_id\"])\n",
    "\n",
    "            # Capture s1 header after the drop to fix the final schema\n",
    "            if subj == \"s1\":\n",
    "                cols_s1 = df.columns.tolist()\n",
    "\n",
    "            # If s1 had been missing, we still proceed with this file's columns\n",
    "            # but once s1 appears later its columns will define the final order\n",
    "            df.insert(0, \"subject\", subj)\n",
    "            frames.append((subj, df, f.name, len(df)))\n",
    "            found.append(f\"{subj}:{len(df)} rows\")\n",
    "        except Exception as e:\n",
    "            missing.append(f\"{subj}:read_error({e})\")\n",
    "\n",
    "    if not frames:\n",
    "        # Nothing to write for this activity\n",
    "        summary.append({\n",
    "            \"activity\": act,\n",
    "            \"output\": str(out_path),\n",
    "            \"rows_total\": 0,\n",
    "            \"found\": found,\n",
    "            \"missing\": missing,\n",
    "        })\n",
    "        continue\n",
    "\n",
    "    # If we have an s1 file, align all frames to s1 columns\n",
    "    # Keep the s1 column order, and drop any extra columns from other subjects\n",
    "    # If s1 is missing, use the first frame's columns as a fallback\n",
    "    if cols_s1 is None:\n",
    "        cols_s1 = frames[0][1].columns.tolist()\n",
    "\n",
    "    # Also make sure subject is the first column in the final output\n",
    "    if \"subject\" in cols_s1:\n",
    "        cols_order = [\"subject\"] + [c for c in cols_s1 if c != \"subject\"]\n",
    "    else:\n",
    "        cols_order = [\"subject\"] + cols_s1\n",
    "\n",
    "    # Reorder and align columns across subjects\n",
    "    aligned = []\n",
    "    for subj, df, name, n in frames:\n",
    "        # Limit to known columns, then add any missing columns as NA\n",
    "        keep = [c for c in df.columns if c in cols_order]\n",
    "        df2 = df[keep].copy()\n",
    "        for c in cols_order:\n",
    "            if c not in df2.columns:\n",
    "                df2[c] = pd.NA\n",
    "        df2 = df2[cols_order]\n",
    "        aligned.append(df2)\n",
    "\n",
    "    stacked = pd.concat(aligned, ignore_index=True)\n",
    "\n",
    "    # Write with a single header line\n",
    "    stacked.to_csv(out_path, index=False)\n",
    "\n",
    "    summary.append({\n",
    "        \"activity\": act,\n",
    "        \"output\": str(out_path),\n",
    "        \"rows_total\": len(stacked),\n",
    "        \"found\": found,\n",
    "        \"missing\": missing,\n",
    "    })\n",
    "\n",
    "# Print summary\n",
    "print(\"=== Stacking summary ===\")\n",
    "total_rows = 0\n",
    "for i, rec in enumerate(summary, start=1):\n",
    "    print(f\"{i:02d}. {rec['activity']}\")\n",
    "    print(f\"    output, {rec['output']}\")\n",
    "    print(f\"    rows_total, {rec['rows_total']}\")\n",
    "    total_rows += rec[\"rows_total\"]\n",
    "    if rec[\"found\"]:\n",
    "        print(f\"    found, {', '.join(rec['found'])}\")\n",
    "    if rec[\"missing\"]:\n",
    "        print(f\"    missing, {', '.join(rec['missing'])}\")\n",
    "\n",
    "print(f\"\\nTotal rows across all outputs, {total_rows:,}\")\n",
    "print(f\"Files written to, {OUT_DIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6debbff0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
