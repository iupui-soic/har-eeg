{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c9c7fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[s1] [WARN] tmp_windows.csv, no valid timestamps in 2025-2025, skipped.\n",
      "[s1] Saved 10 HAR time windows -> /home/jupyter-yin10/EEG_HAR/NEW/data/2_EEG_window_matched/s1/har_time_windows_s1.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3dcb602ec5c4c0aa95c7cf3fc445f7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "s1 filtering:   0%|          | 0/10 [00:00<?, ?file/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[s2] Saved 10 HAR time windows -> /home/jupyter-yin10/EEG_HAR/NEW/data/2_EEG_window_matched/s2/har_time_windows_s2.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "166dec1372ae4ccd9cc8425e8c41a9be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "s2 filtering:   0%|          | 0/10 [00:00<?, ?file/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[s3] Saved 10 HAR time windows -> /home/jupyter-yin10/EEG_HAR/NEW/data/2_EEG_window_matched/s3/har_time_windows_s3.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bd315d1c5bc421e956c26403b034a1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "s3 filtering:   0%|          | 0/10 [00:00<?, ?file/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[s4] Saved 10 HAR time windows -> /home/jupyter-yin10/EEG_HAR/NEW/data/2_EEG_window_matched/s4/har_time_windows_s4.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d8d0c64525541e797aa92d0bdaf9210",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "s4 filtering:   0%|          | 0/10 [00:00<?, ?file/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[s5] Saved 4 HAR time windows -> /home/jupyter-yin10/EEG_HAR/NEW/data/2_EEG_window_matched/s5/har_time_windows_s5.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a5269421a2a4586946279ff223ad61f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "s5 filtering:   0%|          | 0/4 [00:00<?, ?file/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[s6] Saved 10 HAR time windows -> /home/jupyter-yin10/EEG_HAR/NEW/data/2_EEG_window_matched/s6/har_time_windows_s6.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49b089673bb444cdb2bdbd6bd35dd13f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "s6 filtering:   0%|          | 0/10 [00:00<?, ?file/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Per subject totals ===\n",
      " subject  files  rows_before  rows_after  pct_kept  pct_dropped\n",
      "       1     10       147593      126616     85.79        14.21\n",
      "       2     10       111174       95169     85.60        14.40\n",
      "       3     10       112539       91923     81.68        18.32\n",
      "       4     10       108759       86554     79.58        20.42\n",
      "       5      4        29268       28292     96.67         3.33\n",
      "       6     10       106565       89076     83.59        16.41\n",
      "\n",
      "=== Overall totals across s1 to s6 ===\n",
      "Rows before, 615,898\n",
      "Rows after,  517,630\n",
      "Percent kept, 84.04%\n",
      "Percent dropped, 15.96%\n"
     ]
    }
   ],
   "source": [
    "# Process s1..s6, build HAR windows, filter EEG by windows, report totals\n",
    "\n",
    "from pathlib import Path\n",
    "from datetime import timedelta\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "try:\n",
    "    from tqdm.auto import tqdm\n",
    "    use_tqdm = True\n",
    "except Exception:\n",
    "    use_tqdm = False\n",
    "\n",
    "# ===== settings =====\n",
    "SUBJECTS = [1, 2, 3, 4, 5, 6]\n",
    "HAR_BASE = \"/home/jupyter-yin10/EEG_HAR/data/har_convert\"\n",
    "EEG_BASE = \"/home/jupyter-yin10/EEG_HAR/NEW/data/1_EEG_25hz_clean\"\n",
    "OUT_BASE = \"/home/jupyter-yin10/EEG_HAR/NEW/data/2_EEG_window_matched\"\n",
    "YEAR_MIN, YEAR_MAX = 2025, 2025\n",
    "USE_DOMINANT_DAY = True\n",
    "\n",
    "TZ_LOCAL = \"America/Indiana/Indianapolis\"\n",
    "EEG_TIME_IS_UTC = True  # set to False if EEG timestamps are already local\n",
    "\n",
    "# ===== helpers shared =====\n",
    "def safe_read_csv(path):\n",
    "    try:\n",
    "        return pd.read_csv(path, dtype=str, encoding=\"utf-8-sig\", na_filter=False)\n",
    "    except UnicodeDecodeError:\n",
    "        return pd.read_csv(path, dtype=str, encoding=\"utf-8\", na_filter=False)\n",
    "\n",
    "def normalize_leftmost_timestamp(series):\n",
    "    s = series.astype(str)\n",
    "    s = s.str.replace(\"\\u00A0\", \" \", regex=False)\n",
    "    s = s.str.replace(r\"\\s+\", \" \", regex=True).str.strip()\n",
    "    no_sec_mask = s.str.match(r\"^\\d{4}/\\d{1,2}/\\d{1,2}\\s+\\d{1,2}:\\d{2}$\")\n",
    "    s.loc[no_sec_mask] = s.loc[no_sec_mask] + \":00\"\n",
    "    return s\n",
    "\n",
    "def parse_leftmost_timestamp(series):\n",
    "    s = normalize_leftmost_timestamp(series)\n",
    "    dt = pd.to_datetime(s, format=\"%Y/%m/%d %H:%M:%S\", errors=\"coerce\")\n",
    "    return dt\n",
    "\n",
    "def pick_core_times(dt):\n",
    "    dt = dt.dropna()\n",
    "    if dt.empty:\n",
    "        return dt\n",
    "    yr = (dt.dt.year >= YEAR_MIN) & (dt.dt.year <= YEAR_MAX)\n",
    "    dt = dt[yr]\n",
    "    if dt.empty:\n",
    "        return dt\n",
    "    if USE_DOMINANT_DAY:\n",
    "        dom = dt.dt.date.value_counts().idxmax()\n",
    "        dt = dt[dt.dt.date == dom]\n",
    "    return dt\n",
    "\n",
    "def normalize_ts_text(s):\n",
    "    s = s.astype(str)\n",
    "    s = s.str.replace(\"\\u00A0\", \" \", regex=False)\n",
    "    s = s.str.replace(r\"\\s+\", \" \", regex=True).str.strip()\n",
    "    no_sec = s.str.match(r\"^\\d{4}/\\d{1,2}/\\d{1,2}\\s+\\d{1,2}:\\d{2}$\")\n",
    "    s.loc[no_sec] = s.loc[no_sec] + \":00\"\n",
    "    return s\n",
    "\n",
    "def try_parse_dt(series):\n",
    "    s = normalize_ts_text(series)\n",
    "    dt = pd.to_datetime(s, format=\"%Y/%m/%d %H:%M:%S\", errors=\"coerce\")\n",
    "    mask = dt.isna()\n",
    "    if mask.any():\n",
    "        dt2 = pd.to_datetime(s[mask], errors=\"coerce\")\n",
    "        dt.loc[mask] = dt2\n",
    "    return dt\n",
    "\n",
    "def find_eeg_timestamp_column(df):\n",
    "    best_col, best_rate = None, -1.0\n",
    "    for col in df.columns:\n",
    "        dt = try_parse_dt(df[col])\n",
    "        rate = dt.notna().mean()\n",
    "        if rate > best_rate:\n",
    "            best_rate, best_col = rate, col\n",
    "    return best_col if best_rate >= 0.60 else None\n",
    "\n",
    "def per_window_mask_tz(times_tz: pd.Series, windows_df: pd.DataFrame):\n",
    "    keep = pd.Series(False, index=times_tz.index)\n",
    "    first_hit = pd.Series(np.nan, index=times_tz.index)\n",
    "    counts = []\n",
    "    for _, w in windows_df.iterrows():\n",
    "        s = w[\"start\"]\n",
    "        e = w[\"end\"]\n",
    "        m = (times_tz >= s) & (times_tz <= e)\n",
    "        counts.append(int(m.sum()))\n",
    "        first_hit.loc[m & first_hit.isna()] = int(w[\"window_id\"])\n",
    "        keep |= m\n",
    "    return keep, first_hit, counts\n",
    "\n",
    "# ===== runners for a single subject =====\n",
    "def build_windows_for_subject(subj: int) -> Path:\n",
    "    har_dir = Path(HAR_BASE) / f\"s{subj}\"\n",
    "    out_dir = Path(OUT_BASE) / f\"s{subj}\"\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    windows_csv = out_dir / f\"har_time_windows_s{subj}.csv\"\n",
    "\n",
    "    rows = []\n",
    "    for p in sorted(har_dir.glob(\"*.csv\")):\n",
    "        if p.name == windows_csv.name:\n",
    "            continue\n",
    "        df = safe_read_csv(p)\n",
    "        if df.shape[1] == 0:\n",
    "            continue\n",
    "        dt = parse_leftmost_timestamp(df.iloc[:, 0])\n",
    "        dt = pick_core_times(dt)\n",
    "        if dt.empty:\n",
    "            print(f\"[s{subj}] [WARN] {p.name}, no valid timestamps in {YEAR_MIN}-{YEAR_MAX}, skipped.\")\n",
    "            continue\n",
    "\n",
    "        start_raw = dt.min()\n",
    "        end_raw = dt.max()\n",
    "        start_expanded = start_raw - timedelta(seconds=10)\n",
    "        end_expanded = end_raw + timedelta(seconds=10)\n",
    "\n",
    "        rows.append({\n",
    "            \"window_id\": len(rows) + 1,\n",
    "            \"har_file\": p.name,\n",
    "            \"start\": start_expanded.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "            \"end\": end_expanded.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        })\n",
    "\n",
    "    win_df = pd.DataFrame(rows, columns=[\"window_id\", \"har_file\", \"start\", \"end\"])\n",
    "    if win_df.empty:\n",
    "        raise RuntimeError(f\"[s{subj}] No HAR windows built.\")\n",
    "    win_df.to_csv(windows_csv, index=False, encoding=\"utf-8\")\n",
    "    print(f\"[s{subj}] Saved {len(win_df)} HAR time windows -> {windows_csv}\")\n",
    "    return windows_csv\n",
    "\n",
    "def filter_eeg_for_subject(subj: int, windows_csv: Path) -> pd.DataFrame:\n",
    "    eeg_dir = Path(EEG_BASE) / f\"s{subj}\"\n",
    "    out_dir = Path(OUT_BASE) / f\"s{subj}\"\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    win_df = pd.read_csv(windows_csv, dtype={\"window_id\": int, \"har_file\": str, \"start\": str, \"end\": str})\n",
    "    if win_df.empty:\n",
    "        raise RuntimeError(f\"[s{subj}] Windows CSV is empty.\")\n",
    "\n",
    "    win_df[\"start\"] = pd.to_datetime(win_df[\"start\"], errors=\"coerce\").dt.tz_localize(TZ_LOCAL)\n",
    "    win_df[\"end\"]   = pd.to_datetime(win_df[\"end\"],   errors=\"coerce\").dt.tz_localize(TZ_LOCAL)\n",
    "\n",
    "    eeg_csvs = sorted(eeg_dir.glob(\"*.csv\"))\n",
    "    if not eeg_csvs:\n",
    "        print(f\"[s{subj}] No EEG CSVs found in {eeg_dir}\")\n",
    "        return pd.DataFrame(columns=[\"subject\",\"eeg_file\",\"status\",\"rows_before\",\"rows_after\",\"pct_in_window\"])\n",
    "\n",
    "    iterator = tqdm(eeg_csvs, desc=f\"s{subj} filtering\", unit=\"file\") if use_tqdm else eeg_csvs\n",
    "    summary_rows = []\n",
    "\n",
    "    for eeg_path in iterator:\n",
    "        df = safe_read_csv(eeg_path)\n",
    "        before = len(df)\n",
    "        if df.empty:\n",
    "            out_name = f\"{eeg_path.stem}_filtered.csv\"\n",
    "            df.to_csv(out_dir / out_name, index=False, encoding=\"utf-8\")\n",
    "            summary_rows.append([subj, eeg_path.name, \"EMPTY FILE\", before, before, 100.0])\n",
    "            continue\n",
    "\n",
    "        ts_col = find_eeg_timestamp_column(df)\n",
    "        if ts_col is None:\n",
    "            out_name = f\"{eeg_path.stem}_filtered.csv\"\n",
    "            df.to_csv(out_dir / out_name, index=False, encoding=\"utf-8\")\n",
    "            summary_rows.append([subj, eeg_path.name, \"NO TS COL, wrote full file\", before, before, 100.0])\n",
    "            continue\n",
    "\n",
    "        times = try_parse_dt(df[ts_col])\n",
    "        if EEG_TIME_IS_UTC:\n",
    "            times = times.dt.tz_localize(\"UTC\", nonexistent=\"NaT\", ambiguous=\"NaT\").dt.tz_convert(TZ_LOCAL)\n",
    "        else:\n",
    "            times = times.dt.tz_localize(TZ_LOCAL, nonexistent=\"NaT\", ambiguous=\"NaT\")\n",
    "\n",
    "        keep_mask, first_id, counts = per_window_mask_tz(times, win_df)\n",
    "\n",
    "        if not keep_mask.any():\n",
    "            filtered = df.copy()\n",
    "            status = \"NO MATCHES, wrote full file\"\n",
    "            after = before\n",
    "            pct = 100.0\n",
    "        else:\n",
    "            filtered = df[keep_mask].copy()\n",
    "            filtered.insert(0, \"matched_window_id\", first_id[keep_mask].astype(\"Int64\"))\n",
    "            status = \"OK\"\n",
    "            after = len(filtered)\n",
    "            pct = round(after / before * 100.0, 2)\n",
    "\n",
    "        out_name = f\"{eeg_path.stem}_filtered.csv\"\n",
    "        filtered.to_csv(out_dir / out_name, index=False, encoding=\"utf-8\")\n",
    "        summary_rows.append([subj, eeg_path.name, status, before, after, pct])\n",
    "\n",
    "    sum_df = pd.DataFrame(summary_rows, columns=[\"subject\",\"eeg_file\",\"status\",\"rows_before\",\"rows_after\",\"pct_in_window\"])\n",
    "    return sum_df\n",
    "\n",
    "# ===== run all subjects, then print totals =====\n",
    "all_summaries = []\n",
    "for s in SUBJECTS:\n",
    "    windows_csv = build_windows_for_subject(s)\n",
    "    sum_df = filter_eeg_for_subject(s, windows_csv)\n",
    "    if not sum_df.empty:\n",
    "        all_summaries.append(sum_df)\n",
    "\n",
    "if all_summaries:\n",
    "    all_df = pd.concat(all_summaries, ignore_index=True)\n",
    "else:\n",
    "    all_df = pd.DataFrame(columns=[\"subject\",\"eeg_file\",\"status\",\"rows_before\",\"rows_after\",\"pct_in_window\"])\n",
    "\n",
    "# Per subject totals\n",
    "if not all_df.empty:\n",
    "    by_subj = all_df.groupby(\"subject\", as_index=False).agg(\n",
    "        files=(\"eeg_file\", \"count\"),\n",
    "        rows_before=(\"rows_before\", \"sum\"),\n",
    "        rows_after=(\"rows_after\", \"sum\")\n",
    "    )\n",
    "    by_subj[\"pct_kept\"] = (by_subj[\"rows_after\"] / by_subj[\"rows_before\"] * 100).round(2)\n",
    "    by_subj[\"pct_dropped\"] = (100 - by_subj[\"pct_kept\"]).round(2)\n",
    "\n",
    "    # Overall totals\n",
    "    total_before = int(by_subj[\"rows_before\"].sum())\n",
    "    total_after = int(by_subj[\"rows_after\"].sum())\n",
    "    pct_kept = round(total_after / total_before * 100, 2) if total_before > 0 else 0.0\n",
    "    pct_dropped = round(100 - pct_kept, 2)\n",
    "\n",
    "    print(\"\\n=== Per subject totals ===\")\n",
    "    print(by_subj[[\"subject\",\"files\",\"rows_before\",\"rows_after\",\"pct_kept\",\"pct_dropped\"]].to_string(index=False))\n",
    "\n",
    "    print(\"\\n=== Overall totals across s1 to s6 ===\")\n",
    "    print(f\"Rows before, {total_before:,}\")\n",
    "    print(f\"Rows after,  {total_after:,}\")\n",
    "    print(f\"Percent kept, {pct_kept:.2f}%\")\n",
    "    print(f\"Percent dropped, {pct_dropped:.2f}%\")\n",
    "\n",
    "    # Optional, save summaries\n",
    "    out_summary_dir = Path(OUT_BASE)\n",
    "    by_subj.to_csv(out_summary_dir / \"summary_by_subject.csv\", index=False)\n",
    "    all_df.to_csv(out_summary_dir / \"summary_all_files.csv\", index=False)\n",
    "else:\n",
    "    print(\"No summaries to report.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e433ee91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
